{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5249931e",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook demonstrates a workflow for transforming tabular data extracted from PDFs into a searchable vector store for downstream retrieval tasks.\n",
    "\n",
    "## Main Steps\n",
    "\n",
    "1. **Transform Table Rows to JSON**\n",
    "   - Reads all CSV files matching `output_table*.csv`.\n",
    "   - Cleans table headers for consistency.\n",
    "   - Converts each row to a structured JSON object containing the table name, a text representation of the row, and metadata (page number, column names).\n",
    "   \n",
    "```json\n",
    "{\n",
    "    \n",
    "    \"text\": \"<column1>: <value1> | <column2>: <value2> | ...\",\n",
    "    \"metadata\": {\n",
    "         \"table_name\": \"<name>\",\n",
    "        \"page\": <page_number>,\n",
    "        \"columns\": [<column_names>]\n",
    "    }\n",
    "}\n",
    "```\n",
    "   - Saves the resulting JSON objects to new files.\n",
    "\n",
    "2. **Build a Vector Store**\n",
    "   - Loads the generated JSON files.\n",
    "   - Converts each JSON object into a `Document` for use with vector databases.\n",
    "   - Uses a sentence transformer model to create embeddings.\n",
    "   - Stores the embeddings in a FAISS vector store for efficient similarity search.\n",
    "\n",
    "3. **Query the Vector Store**\n",
    "   - Demonstrates how to retrieve the most relevant table rows for a given query using the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68143743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "\n",
    "file_names = glob.glob(\"../data/output_table*.csv\")\n",
    "\n",
    "def clean_header(df):\n",
    "    # replace special chars and spaces with underscores in headers\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(r'[^A-Za-z0-9]+', '_', regex=True).str.strip('_')\n",
    "    df.columns = df.columns.str.replace('_none', '')\n",
    "    return df\n",
    "\n",
    "def chunk(row, table_name, page_num):\n",
    "    text = \" | \".join(f\"{col}: {val}\" for col, val in row.items() if pd.notna(val))\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"metadata\": {\n",
    "            \"table_name\": table_name,\n",
    "            \"page\": page_num,\n",
    "            \"columns\": list(row.index)\n",
    "        }\n",
    "    }\n",
    "for file in file_names:\n",
    "    df = pd.read_csv(file)\n",
    "    df = clean_header(df)\n",
    "    table_name = file.split(\"\\\\\")[-1].replace(\".csv\", \"\")\n",
    "    match = re.search(r'table(\\d+)', file)\n",
    "    page_num = int(match.group(1)) if match else -1\n",
    "    chunks = [chunk(row, table_name, page_num) for _, row in df.iterrows()]\n",
    "    json.dump(chunks, open(file.replace(\".csv\", \".json\"), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "431fca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob \n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "file_names = glob.glob(\"../data/output_table*.json\")\n",
    "documents = []\n",
    "for file in file_names:\n",
    "    with open(file, \"r\") as f:\n",
    "        chunks = json.load(f)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        document = Document(\n",
    "            page_content=chunk[\"text\"],\n",
    "            metadata=chunk[\"metadata\"]\n",
    "        )\n",
    "        documents.append(document)\n",
    "    \n",
    "# Create embedding model\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(documents, embeddings)\n",
    "vector_store.save_local(\"../data/faiss_index\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "614002d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "Text: substance: Arsenic | type_of_trv: Inhalation UR | trv_value: 6.4E+00\n",
      "(mg/m3)–¹ | study_details: Study Type: epidemiological\n",
      "(occupational)\n",
      "Species: humans\n",
      "Mode of Exposure: inhalation\n",
      "Exposure Concentrations: N/A\n",
      "Duration: chronic\n",
      "Uncertainty Factors: N/A | threshold_non_threshold_endpoint: TC (5% tumourigenic\n",
      "05\n",
      "concentration) =\n",
      "7.83 µg/m³ | trv_derivation_method: Relative risk model\n",
      "Inhalation UR =\n",
      "0.05/TC\n",
      "05\n",
      "where 0.05 = 5% extra\n",
      "cancer risk | critical_effect_s: Cancer\n",
      "(lung) | source: EC and HC, 1993a\n",
      "(based on\n",
      "Higgins et al.,\n",
      "1986)\n",
      "Metadata: {'table_name': 'output_table24', 'page': 24, 'columns': ['substance', 'type_of_trv', 'trv_value', 'study_details', 'threshold_non_threshold_endpoint', 'trv_derivation_method', 'critical_effect_s', 'carcinogenicity_classification', 'source']}\n"
     ]
    }
   ],
   "source": [
    "def retrieve(query, k=3):\n",
    "    \"\"\"\n",
    "    Retrieve top-k relevant documents from FAISS vector store.\n",
    "    \"\"\"\n",
    "    results = vector_store.similarity_search(query, k=k)\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"\\nResult {i+1}:\")\n",
    "        print(\"Text:\", doc.page_content)\n",
    "        print(\"Metadata:\", doc.metadata)\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.load_local(\"../data/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "query = \"Arsenic TRV value Inhalation\"\n",
    "retrieve(query, k=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
